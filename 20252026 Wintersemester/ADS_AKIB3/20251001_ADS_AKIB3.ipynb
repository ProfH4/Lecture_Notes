{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af65d5ed-cc86-4764-8e00-9c9983a6d815",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1D-Regression (Formeln): a = -0.500, b = 0.090, MSE = 0.3800\n",
      "1D-GD: a = nan, b = nan, MSE = nan\n",
      "Mehrdimensional (LS-Solver): w_hat = [ 1.469  1.992 -3.12 ] | MSE = 0.632\n",
      "Standardisiert + Train/Test: MSE_train = 0.554 | MSE_test = 0.915\n",
      "Korrelationsmatrix der Features:\n",
      " [[1.    0.147]\n",
      " [0.147 1.   ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nw/k_k0_cbj7vl_npdmryvhl53c0000gn/T/ipykernel_37339/1750272478.py:71: RuntimeWarning: overflow encountered in multiply\n",
      "  db = (-2.0 / n) * np.sum(x * (y - y_pred))\n",
      "/var/folders/nw/k_k0_cbj7vl_npdmryvhl53c0000gn/T/ipykernel_37339/1750272478.py:79: RuntimeWarning: invalid value encountered in scalar subtract\n",
      "  b -= lr * db\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Applied Data Science – Vorlesung 1\n",
    "\n",
    "Dieses Skript implementiert GENAU die in Teil A definierten Konzepte:\n",
    "- Listen/Vektoren, Mittelwert, Varianz (mit n im Nenner), Kovarianz, Korrelation, Standardisierung\n",
    "- 1D-Regression: a = ȳ - b x̄, b = Cov(x, y) / Var(x)\n",
    "- MSE als Zielfunktion\n",
    "- Gradient Descent in 1D (nur mit den Ableitungsregeln aus A3)\n",
    "- Mehrere Merkmale mit Designmatrix + eingebautem Least-Squares-Solver (ohne LA-Details)\n",
    "- Train/Test-Aufteilung und Test-MSE\n",
    "Hinweis: Nur NumPy wird genutzt.\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 0) Statistik-Helfer (konsistent zu A1: Mittelwert, Varianz(n), Kovarianz(n), Korrelation)\n",
    "# ------------------------------------------------------------\n",
    "def mean(v):\n",
    "    return np.sum(v) / v.shape[0]\n",
    "\n",
    "def var_n(v):  # Varianz mit n im Nenner (wie in A1/A7)\n",
    "    m = mean(v)\n",
    "    return np.sum((v - m)**2) / v.shape[0]\n",
    "\n",
    "def std_n(v):\n",
    "    return np.sqrt(var_n(v))\n",
    "\n",
    "def cov_n(x, y):  # Kovarianz mit n im Nenner (wie in A1/A7)\n",
    "    mx, my = mean(x), mean(y)\n",
    "    return np.sum((x - mx) * (y - my)) / x.shape[0]\n",
    "\n",
    "def corr_xy(x, y):\n",
    "    sx, sy = std_n(x), std_n(y)\n",
    "    if sx == 0 or sy == 0: \n",
    "        return 0.0\n",
    "    return cov_n(x, y) / (sx * sy)\n",
    "\n",
    "def standardize(x):\n",
    "    mu, sd = mean(x), std_n(x)\n",
    "    z = (x - mu) / (sd + 1e-12)\n",
    "    return z, mu, sd\n",
    "\n",
    "def mse(y_true, y_pred):\n",
    "    r = y_true - y_pred\n",
    "    return np.mean(r**2)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 1) 1D-Regression genau wie in A7\n",
    "# ------------------------------------------------------------\n",
    "x = np.array([30, 40, 50, 60, 70], dtype=float)\n",
    "y = np.array([ 2,  3,  5,  4,  6], dtype=float)  # y in 100 €\n",
    "\n",
    "xb, yb = mean(x), mean(y)\n",
    "b = cov_n(x, y) / var_n(x)   # b = Cov/Var (mit n)\n",
    "a = yb - b * xb              # a = ȳ - b x̄\n",
    "y_hat = a + b * x\n",
    "\n",
    "print(\"1D-Regression (Formeln): a = %.3f, b = %.3f, MSE = %.4f\" % (a, b, mse(y, y_hat)))\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 2) Gradient Descent in 1D – genau gemäß A3 (Ableitungen)\n",
    "#    MSE(a,b) = (1/n) * sum (y_i - (a + b x_i))^2\n",
    "#    dMSE/da = (-2/n) * sum (y_i - (a + b x_i))\n",
    "#    dMSE/db = (-2/n) * sum (x_i * (y_i - (a + b x_i)))\n",
    "# ------------------------------------------------------------\n",
    "def grad_mse_1d(a, b, x, y):\n",
    "    n = x.shape[0]\n",
    "    y_pred = a + b * x\n",
    "    da = (-2.0 / n) * np.sum(y - y_pred)\n",
    "    db = (-2.0 / n) * np.sum(x * (y - y_pred))\n",
    "    return da, db\n",
    "\n",
    "def fit_gd_1d(x, y, a0=0.0, b0=0.0, lr=1e-3, steps=20000):\n",
    "    a, b = a0, b0\n",
    "    for _ in range(steps):\n",
    "        da, db = grad_mse_1d(a, b, x, y)\n",
    "        a -= lr * da\n",
    "        b -= lr * db\n",
    "    return a, b\n",
    "\n",
    "a_gd, b_gd = fit_gd_1d(x, y, lr=1e-3, steps=20000)\n",
    "print(\"1D-GD: a = %.3f, b = %.3f, MSE = %.4f\" % (a_gd, b_gd, mse(y, a_gd + b_gd * x)))\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 3) Mehrere Merkmale: Designmatrix + Least Squares (ohne Pseudoinverse erklären)\n",
    "#    Wir erzeugen synthetische Daten mit 2 Merkmalen und nutzen einen eingebauten Least-Squares-Solver.\n",
    "# ------------------------------------------------------------\n",
    "rng = np.random.default_rng(0)\n",
    "n, d = 120, 2\n",
    "X_feats = rng.normal(size=(n, d))          # zwei Merkmale/Spalten\n",
    "w_true = np.array([2.0, -3.0])\n",
    "bias_true = 1.5\n",
    "noise = rng.normal(0, 0.8, size=n)\n",
    "y_multi = bias_true + X_feats @ w_true + noise\n",
    "\n",
    "# Designmatrix: linke Spalte = 1 für den Achsenabschnitt 'a'\n",
    "X_design = np.c_[np.ones(n), X_feats]      # Form (n, d+1)\n",
    "# Eingebauter Least-Squares-Solver: minimiert direkt die MSE\n",
    "w_hat, *_ = np.linalg.lstsq(X_design, y_multi, rcond=None)  # w_hat = [a, w1, w2]\n",
    "mse_multi = mse(y_multi, X_design @ w_hat)\n",
    "print(\"Mehrdimensional (LS-Solver): w_hat =\", np.round(w_hat, 3), \"| MSE =\", round(mse_multi, 3))\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 4) Standardisierung & Train/Test – Definitionen aus A6 umgesetzt\n",
    "# ------------------------------------------------------------\n",
    "# Train/Test-Split: zufällige Permutation, 75%/25%\n",
    "perm = rng.permutation(n)\n",
    "n_train = int(0.75 * n)\n",
    "idx_tr, idx_te = perm[:n_train], perm[n_train:]\n",
    "\n",
    "X_tr, X_te = X_feats[idx_tr], X_feats[idx_te]\n",
    "y_tr, y_te = y_multi[idx_tr], y_multi[idx_te]\n",
    "\n",
    "# Standardisierung NUR auf Train fitten, dann auf Test anwenden\n",
    "mu = X_tr.mean(axis=0)\n",
    "sd = X_tr.std(axis=0) + 1e-12\n",
    "X_tr_std = (X_tr - mu) / sd\n",
    "X_te_std = (X_te - mu) / sd\n",
    "\n",
    "# Designmatrizen wieder mit 1-Spalte:\n",
    "Xtr = np.c_[np.ones(X_tr_std.shape[0]), X_tr_std]\n",
    "Xte = np.c_[np.ones(X_te_std.shape[0]), X_te_std]\n",
    "\n",
    "# Least Squares auf Train, MSE auf Train und Test berichten\n",
    "w_tr, *_ = np.linalg.lstsq(Xtr, y_tr, rcond=None)\n",
    "mse_tr = mse(y_tr, Xtr @ w_tr)\n",
    "mse_te = mse(y_te, Xte @ w_tr)\n",
    "print(\"Standardisiert + Train/Test: MSE_train =\", round(mse_tr,3), \"| MSE_test =\", round(mse_te,3))\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 5) Korrelation der Merkmale (definiert in A1)\n",
    "# ------------------------------------------------------------\n",
    "def corr_matrix_cols(M):\n",
    "    # M: (n, d) – berechnet paarweise Korrelationen der Spalten gemäß Corr = Cov/(Std*Std)\n",
    "    d = M.shape[1]\n",
    "    R = np.zeros((d, d))\n",
    "    for i in range(d):\n",
    "        for j in range(d):\n",
    "            R[i, j] = corr_xy(M[:, i], M[:, j])\n",
    "    return R\n",
    "\n",
    "R = corr_matrix_cols(X_feats)\n",
    "print(\"Korrelationsmatrix der Features:\\n\", np.round(R, 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d24a333-99cf-4802-bd59-e163ada6a068",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
